{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent neural network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Forward propagation implementation of SimpleRNN"
      ],
      "metadata": {
        "id": "BljqZT9oD2tm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GOIAogxfDI3I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def forward(xt,h):\n",
        "  for i in range(n_sequences):\n",
        "    at = xt[:,i,:] @ w_x  + h @ w_h + b\n",
        "    h = np.tanh(at)\n",
        "  return h\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment of forward propagation with small sequence"
      ],
      "metadata": {
        "id": "Oc0YxtzFLPb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
        "batch_size = x.shape[0] # 1\n",
        "n_sequences = x.shape[1] # 3\n",
        "n_features = x.shape[2] # 2\n",
        "n_nodes = w_x.shape[1] # 4\n",
        "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
        "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
      ],
      "metadata": {
        "id": "ADR5gjHhLLn6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward(x,h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YIMOTClLRUc",
        "outputId": "d1a1a358-be22-4afd-9406-cf63bd6ac7bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of backpropagation"
      ],
      "metadata": {
        "id": "Ow-P52zpLrrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\alpha$: learning rate\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_x}$: Loss $L$ slope for $W_x$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_h}$: Loss $L$ slope for $W_h$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B}$: slope of loss $L$ with respect to $B$\n",
        "\n",
        "The backpropagation formula for the slope is:\n",
        "\n",
        "$\\frac{\\partial h_t}{\\partial a_t} = \\frac{\\partial L}{\\partial h_t} Ã— (1-tanh^2(a_t))$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B} = \\frac{\\partial h_t}{\\partial a_t}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_x} = x_{t}^{T}\\cdot \\frac{\\partial h_t}{\\partial a_t}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_h} = h_{t-1}^{T}\\cdot \\frac{\\partial h_t}{\\partial a_t}$\n",
        "\n",
        "*$\\frac{\\partial L}{\\partial h_t}$ is the sum of the state error and the output error from the previous time. This is because h is used for both the output and the state transmitted to the next layer during forward propagation.\n",
        "\n",
        "The formula of the error sent to the previous time and layer is as follows.\n",
        "\n",
        "$\\frac{\\partial L}{\\partial h_{t-1}} = \\frac{\\partial h_t}{\\partial a_t}\\cdot W_{h}^{T}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial x_{t}} = \\frac{\\partial h_t}{\\partial a_t}\\cdot W_{x}^{T}$"
      ],
      "metadata": {
        "id": "rKkOFlUOOdys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def backward(dh):\n",
        "  h = [np.random.randn(*dh.shape) for i in range(n_sequences) ]\n",
        "  dB = np.random.randn(*b.shape) \n",
        "  dWx = np.random.randn(*w_x.shape)\n",
        "  dWh = np.random.randn(*w_h.shape)\n",
        "  # h = np.zeros((batch_size, n_nodes))\n",
        "  dA = dh * (1 - np.tanh(dh)**2)\n",
        "  for i in range(n_sequences, 0, -1):\n",
        "    dB += np.sum(dA, axis=0)\n",
        "    dWx += x[:, i-1, :].T @ dA\n",
        "    dWh += h[i-1].T @ dA\n",
        "\n",
        "  # print(dA.shape)\n",
        "  # print(w_x.shape)\n",
        "  dx = dA @ w_x.T\n",
        "\n",
        "  dh = dA @ w_h.T\n",
        "  return dx, dh"
      ],
      "metadata": {
        "id": "p-wL8ttsLgM7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backward(forward(x,h))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfthRVkRUfV1",
        "outputId": "86b039a9-8dfc-444a-9aaf-0ad7ec60ad17"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.07116008, 0.10237068]]),\n",
              " array([[0.07116008, 0.08898292, 0.10237068, 0.1246286 ]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6ZfheIGxZRf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
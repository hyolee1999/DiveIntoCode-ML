{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    Depth 1 decision tree classifier scratch implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.verbose = verbose\n",
    "        self.max_depth = 1\n",
    "        self.current_depth = 0\n",
    "        self.min_size =1\n",
    "        self.node = {}\n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def gini_index(self,groups, classes):\n",
    "        # count all samples at split point\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = [row[-1] for row in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "    \n",
    "    def test_split(self,index, value, dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "    \n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self,group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self,node, max_depth, min_size, depth):\n",
    "        left, right = node['groups']\n",
    "        del(node['groups'])\n",
    "        # check for a no split\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.to_terminal(left + right)\n",
    "            self.current_depth = depth\n",
    "            return\n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            self.current_depth = depth\n",
    "            return\n",
    "        # process left child\n",
    "        if len(left) <= min_size:\n",
    "            node['left'] = self.to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = self.get_split(left)\n",
    "            self.split(node['left'], max_depth, min_size, depth+1)\n",
    "        # process right child\n",
    "        if len(right) <= min_size:\n",
    "            node['right'] = self.to_terminal(right)\n",
    "        else:\n",
    "            node['right'] = self.get_split(right)\n",
    "            self.split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "    # Select the best split point for a dataset\n",
    "    def get_split(self,X):\n",
    "        class_values = list(set(row[-1] for row in X))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        for index in range(len(X[0])-1):\n",
    "            for row in X:\n",
    "                groups = self.test_split(index, row[index], X)\n",
    "                gini = self.gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Learn the decision tree classifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Training dataの特徴量\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        \"\"\"\n",
    "        X = np.concatenate([X,np.expand_dims(y,axis = 1)],axis = 1)\n",
    "        self.node = self.get_split(X)\n",
    "        self.split(self.node, self.max_depth, self.min_size, 1)\n",
    "#         return root\n",
    "        if self.verbose:\n",
    "#             Output the learning process when #verbose is set to True\n",
    "            self.print_tree(self.node, self.current_depth)\n",
    "#         pass\n",
    "\n",
    "    def print_tree(self,node, depth=0):\n",
    "       \n",
    "        if isinstance(node, dict):\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "            self.print_tree(node['left'], depth+1)\n",
    "            self.print_tree(node['right'], depth+1)\n",
    "        else:\n",
    "            print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the label using a decision tree classifier\n",
    "        \"\"\"\n",
    "        if X.ndim == 1 or X.shape[0] == 1:\n",
    "            if X[self.node['index']] < self.node['value']:\n",
    "                if isinstance(self.node['left'], dict):\n",
    "                    return self.predict_recur(self.node['left'], X)\n",
    "                else:\n",
    "                    return self.node['left']\n",
    "            else:\n",
    "                if isinstance(self.node['right'], dict):\n",
    "                    return self.predict_recur(self.node['right'], X)\n",
    "                else:\n",
    "                    return self.node['right']\n",
    "        else:\n",
    "            predictions = []\n",
    "            for x in X:\n",
    "                if x[self.node['index']] < self.node['value']:\n",
    "                    if isinstance(self.node['left'], dict):\n",
    "                        predictions.append(self.predict_recur(self.node['left'], x))\n",
    "                    else:\n",
    "                        predictions.append(self.node['left'])\n",
    "                else:\n",
    "                    if isinstance(self.node['right'], dict):\n",
    "                        predictions.append(self.predict_recur(self.node['right'], x))\n",
    "                    else:\n",
    "                        predictions.append(self.node['right'])\n",
    "            return np.array(predictions)\n",
    "            \n",
    "    def predict_recur(self,node,X):\n",
    "        if X[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict_recur(node['left'], X)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict_recur(node['right'], X)\n",
    "            else:\n",
    "                return node['right']\n",
    "#         pass\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScratchDecesionTreeClassifierDepth1(verbose =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n",
    "])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [X2 < 5.352]\n",
      "  [0.0]\n",
      "  [1.0]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = []\n",
    "# for sample in range(len(X)):\n",
    "#     predict.append(model.predict(X[sample]))\n",
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecisionTreeClassifierDepth2():\n",
    "    \"\"\"\n",
    "    Depth 1 decision tree classifier scratch implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.verbose = verbose\n",
    "        self.max_depth = 2\n",
    "        self.current_depth = 0\n",
    "        self.min_size =1\n",
    "        self.node = {}\n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def gini_index(self,groups, classes):\n",
    "        # count all samples at split point\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = [row[-1] for row in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "    \n",
    "    def test_split(self,index, value, dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "    \n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self,group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self,node, max_depth, min_size, depth):\n",
    "        left, right = node['groups']\n",
    "        del(node['groups'])\n",
    "        # check for a no split\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.to_terminal(left + right)\n",
    "            self.current_depth = depth\n",
    "            return\n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            self.current_depth = depth\n",
    "            return\n",
    "        # process left child\n",
    "        if len(left) <= min_size:\n",
    "            node['left'] = self.to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = self.get_split(left)\n",
    "            self.split(node['left'], max_depth, min_size, depth+1)\n",
    "        # process right child\n",
    "        if len(right) <= min_size:\n",
    "            node['right'] = self.to_terminal(right)\n",
    "        else:\n",
    "            node['right'] = self.get_split(right)\n",
    "            self.split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "    # Select the best split point for a dataset\n",
    "    def get_split(self,X):\n",
    "        class_values = list(set(row[-1] for row in X))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        for index in range(len(X[0])-1):\n",
    "            for row in X:\n",
    "                groups = self.test_split(index, row[index], X)\n",
    "                gini = self.gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Learn the decision tree classifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Training dataの特徴量\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        \"\"\"\n",
    "        X = np.concatenate([X,np.expand_dims(y,axis = 1)],axis = 1)\n",
    "        self.node = self.get_split(X)\n",
    "        self.split(self.node, self.max_depth, self.min_size, 1)\n",
    "#         return root\n",
    "        if self.verbose:\n",
    "#             Output the learning process when #verbose is set to True\n",
    "            self.print_tree(self.node, self.current_depth)\n",
    "#         pass\n",
    "\n",
    "    def print_tree(self,node, depth=0):\n",
    "       \n",
    "        if isinstance(node, dict):\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "            self.print_tree(node['left'], depth+1)\n",
    "            self.print_tree(node['right'], depth+1)\n",
    "        else:\n",
    "            print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the label using a decision tree classifier\n",
    "        \"\"\"\n",
    "     \n",
    "        if X.ndim == 1 or X.shape[0] == 1 :\n",
    "            if X[self.node['index']] < self.node['value']:\n",
    "                if isinstance(self.node['left'], dict):\n",
    "                    return self.predict_recur(self.node['left'], X)\n",
    "                else:\n",
    "                    return self.node['left']\n",
    "            else:\n",
    "                if isinstance(self.node['right'], dict):\n",
    "                    return self.predict_recur(self.node['right'], X)\n",
    "                else:\n",
    "                    return self.node['right']\n",
    "        else:\n",
    "            predictions = []\n",
    "            for x in X:\n",
    "                if x[self.node['index']] < self.node['value']:\n",
    "                    if isinstance(self.node['left'], dict):\n",
    "                        predictions.append(self.predict_recur(self.node['left'], x))\n",
    "                    else:\n",
    "                        predictions.append(self.node['left'])\n",
    "                else:\n",
    "                    if isinstance(self.node['right'], dict):\n",
    "                        predictions.append(self.predict_recur(self.node['right'], x))\n",
    "                    else:\n",
    "                        predictions.append(self.node['right'])\n",
    "            return np.array(predictions)\n",
    "            \n",
    "            \n",
    "    def predict_recur(self,node,X):\n",
    "        if X[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict_recur(node['left'], X)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict_recur(node['right'], X)\n",
    "            else:\n",
    "                return node['right']\n",
    "#         pass\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScratchDecisionTreeClassifierDepth2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepthInf():\n",
    "    \"\"\"\n",
    "    Depth 1 decision tree classifier scratch implementation\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.verbose = verbose\n",
    "        self.max_depth = np.Inf\n",
    "        self.current_depth = 0\n",
    "        self.min_size =1\n",
    "        self.node = {}\n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def gini_index(self,groups, classes):\n",
    "        # count all samples at split point\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = [row[-1] for row in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "    \n",
    "    def test_split(self,index, value, dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "    \n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self,group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self,node, max_depth, min_size, depth):\n",
    "        left, right = node['groups']\n",
    "        del(node['groups'])\n",
    "        # check for a no split\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.to_terminal(left + right)\n",
    "            self.current_depth = depth\n",
    "            return\n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            self.current_depth = depth\n",
    "            return\n",
    "        # process left child\n",
    "        if len(left) <= min_size:\n",
    "            node['left'] = self.to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = self.get_split(left)\n",
    "            self.split(node['left'], max_depth, min_size, depth+1)\n",
    "        # process right child\n",
    "        if len(right) <= min_size:\n",
    "            node['right'] = self.to_terminal(right)\n",
    "        else:\n",
    "            node['right'] = self.get_split(right)\n",
    "            self.split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "    # Select the best split point for a dataset\n",
    "    def get_split(self,X):\n",
    "        class_values = list(set(row[-1] for row in X))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        for index in range(len(X[0])-1):\n",
    "            for row in X:\n",
    "                groups = self.test_split(index, row[index], X)\n",
    "                gini = self.gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Learn the decision tree classifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Training dataの特徴量\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        \"\"\"\n",
    "        X = np.concatenate([X,np.expand_dims(y,axis = 1)],axis = 1)\n",
    "        self.node = self.get_split(X)\n",
    "        self.split(self.node, self.max_depth, self.min_size, 1)\n",
    "#         return root\n",
    "        if self.verbose:\n",
    "#             Output the learning process when #verbose is set to True\n",
    "            self.print_tree(self.node, self.current_depth)\n",
    "#         pass\n",
    "\n",
    "    def print_tree(self,node, depth=0):\n",
    "       \n",
    "        if isinstance(node, dict):\n",
    "            print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "            self.print_tree(node['left'], depth+1)\n",
    "            self.print_tree(node['right'], depth+1)\n",
    "        else:\n",
    "            print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the label using a decision tree classifier\n",
    "        \"\"\"\n",
    "        if X.ndim == 1 or X.shape[0] == 1 :\n",
    "            if X[self.node['index']] < self.node['value']:\n",
    "                if isinstance(self.node['left'], dict):\n",
    "                    return self.predict_recur(self.node['left'], X)\n",
    "                else:\n",
    "                    return self.node['left']\n",
    "            else:\n",
    "                if isinstance(self.node['right'], dict):\n",
    "                    return self.predict_recur(self.node['right'], X)\n",
    "                else:\n",
    "                    return self.node['right']\n",
    "        else:\n",
    "            predictions = []\n",
    "            for x in X:\n",
    "                if x[self.node['index']] < self.node['value']:\n",
    "                    if isinstance(self.node['left'], dict):\n",
    "                        predictions.append(self.predict_recur(self.node['left'], x))\n",
    "                    else:\n",
    "                        predictions.append(self.node['left'])\n",
    "                else:\n",
    "                    if isinstance(self.node['right'], dict):\n",
    "                        predictions.append(self.predict_recur(self.node['right'], x))\n",
    "                    else:\n",
    "                        predictions.append(self.node['right'])\n",
    "            return np.array(predictions)\n",
    "        \n",
    "    def predict_recur(self,node,X):\n",
    "        if X[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict_recur(node['left'], X)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict_recur(node['right'], X)\n",
    "            else:\n",
    "                return node['right']\n",
    "#         pass\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScratchDecesionTreeClassifierDepthInf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, predict, target_names=[\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.6797, 2.4602999999997834, -5.353, 16.666999999999533)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_classes = len(np.unique(y))\n",
    "plot_colors = \"ryb\"\n",
    "plot_step = 0.02\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2],\n",
    "                                [1, 2], [1, 3]]):\n",
    "    # We only take the two corresponding features\n",
    " \n",
    "\n",
    "    # Train\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=str(np.unique(y)[i]),\n",
    "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "\n",
    "plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
    "plt.legend(loc='lower right', borderpad=0, handletextpad=0)\n",
    "plt.axis(\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

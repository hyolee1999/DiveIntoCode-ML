{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLogisticRegression():\n",
    "    \"\"\"\n",
    "    Scratch implementation of logistic regression\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      Number of iterations\n",
    "    lr : float\n",
    "      Learning rate\n",
    "    no_bias : bool\n",
    "      True if no bias term is included\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : The following form of ndarray, shape (n_features,)\n",
    "      Parameters\n",
    "    self.loss : The following form of ndarray, shape (self.iter,)\n",
    "      Record losses on training data\n",
    "    self.val_loss : The following form of ndarray, shape (self.iter,)\n",
    "      Record loss on validation data\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # Prepare an array to record the loss\n",
    "        self.coef = np.zeros(2)\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Learn logistic regression. If validation data is entered, the loss and accuracy for it are also calculated for each iteration.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        X_val : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of verification data\n",
    "        y_val : The following form of ndarray, shape (n_samples,)\n",
    "            Correct value of verification data\n",
    "        \"\"\"\n",
    "        \n",
    "        self.coef = np.zeros(X.shape[1])\n",
    "        for i in range(self.iter):\n",
    "            loss = self.gradient_descent(X,y)\n",
    "#             print(loss)\n",
    "            sum_loss = np.sum(loss)\n",
    "            self.loss[i] = sum_loss\n",
    "\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_loss = self.compute_cost(X_val,y_val)\n",
    "                sum_val_loss = np.sum(val_loss)\n",
    "                self.val_loss[i] = sum_val_loss\n",
    "                if self.verbose and i%10000 ==0:\n",
    "                   print(\"Loss train iteration {} is {}\".format(i,sum_loss)) \n",
    "                   print(\"Loss val iteration {} is {}\".format(i,sum_val_loss)) \n",
    "                if self.early_stopping(self.loss,i,self.val_loss):\n",
    "                    break\n",
    "            else:\n",
    "                if self.verbose and i%10000 ==0:\n",
    "                    print(\"Loss train iteration {} is {}\".format(i,sum_loss) )\n",
    "                if self.early_stopping(self.loss,i):\n",
    "                    break\n",
    "     \n",
    "    \n",
    "    \n",
    "    def early_stopping(self,train_loss,iteration,val_loss =None):\n",
    "        \n",
    "        if iteration ==0:\n",
    "            return False\n",
    "        \n",
    "#         if val_loss is not None:\n",
    "#             if val_loss[int(iteration)] > val_loss[int(iteration) -1 ]:\n",
    "#                 return True\n",
    "#             else:\n",
    "#                 return False\n",
    "#         else:\n",
    "\n",
    "        if train_loss[int(iteration)] > train_loss[int(iteration) -1 ]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def compute_cost(self,X, y):\n",
    "        m = len(y)\n",
    "#         print(self.coef)\n",
    "        h = self.sigmoid(X @ self.coef )\n",
    "        epsilon = 1e-5\n",
    "        cost = (1/m)*(((-y).T @ np.log(h + epsilon))-((1-y).T @ np.log(1-h + epsilon)))\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def gradient_descent(self,X, y):\n",
    "        m = len(y)\n",
    "\n",
    "        self.coef = self.coef - (self.lr/m) * (X.T @ (self.sigmoid(X @ self.coef ) - y)) \n",
    "\n",
    "\n",
    "        return self.compute_cost(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the label using logistic regression.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            sample\n",
    "        Returns\n",
    "        -------\n",
    "            The following form of ndarray, shape (n_samples, 1)\n",
    "            Estimated result by logistic regression\n",
    "        \"\"\"\n",
    "        return np.round(self.sigmoid(X @  self.coef))\n",
    "       \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Estimate the probability using logistic regression.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            sample\n",
    "        Returns\n",
    "        -------\n",
    "            The following form of ndarray, shape (n_samples, 1)\n",
    "            Estimated result by logistic regression\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.sigmoid(X.T @  self.coef)\n",
    "    def save(self,name, type=\"numpy\"):\n",
    "        if type == \"numpy\":\n",
    "            np.savez(name,self.coef)\n",
    "        elif type == \"pickle\":\n",
    "            with open(str(name) +'.pickle', 'wb') as handle:\n",
    "                pickle.dump(self.coef, handle)\n",
    "                \n",
    "    def load(self,name, type=\"numpy\"):\n",
    "        if type == \"numpy\":\n",
    "            self.coef = np.load(name+\".npz\")\n",
    "        elif type == \"pickle\":\n",
    "            with open(str(name) +'.pickle', 'rb') as handle:\n",
    "                self.coef = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data \n",
    "target = iris.target \n",
    "names = iris.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'] = iris.target\n",
    "# df['species'] = df['species'].replace(to_replace= [0, 1, 2], value = ['setosa', 'versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['species'] = df['species'].replace(to_replace= ['setosa', 'versicolor', 'virginica'], value = [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df['species'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\LV\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['species'] = data['species'].replace(to_replace= [1, 2], value = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)', 'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScratchLogisticRegression(num_iter =100000000 , lr = 0.03, bias = 2, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
    "       'petal width (cm)']].values , data['species'].values , test_size=0.1, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train iteration 0 is 0.6878195105044322\n",
      "Loss val iteration 0 is 0.6992790256894046\n",
      "Loss train iteration 10000 is 0.1389776655425346\n",
      "Loss val iteration 10000 is 0.07210334705969468\n",
      "Loss train iteration 20000 is 0.1257055546534399\n",
      "Loss val iteration 20000 is 0.05767893899976478\n",
      "Loss train iteration 30000 is 0.12139841489034132\n",
      "Loss val iteration 30000 is 0.0514250824515271\n",
      "Loss train iteration 40000 is 0.11943382039847449\n",
      "Loss val iteration 40000 is 0.0478858300074512\n",
      "Loss train iteration 50000 is 0.11838660944962358\n",
      "Loss val iteration 50000 is 0.04564482757074729\n",
      "Loss train iteration 60000 is 0.117775164120842\n",
      "Loss val iteration 60000 is 0.04413069548661182\n",
      "Loss train iteration 70000 is 0.1173961420827946\n",
      "Loss val iteration 70000 is 0.04306160056063588\n",
      "Loss train iteration 80000 is 0.11715110410780684\n",
      "Loss val iteration 80000 is 0.04228149513440546\n",
      "Loss train iteration 90000 is 0.11698771709528673\n",
      "Loss val iteration 90000 is 0.04169722036283995\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict, target_names=[\"a\",\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "sns.set_style('white')\n",
    "plt.plot(range(len(model.loss)), model.loss, 'r')\n",
    "plt.title(\"Convergence Graph of Cost Function\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = float(sum(y_predict == y_test))/ float(len(y_test))\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# X_Train_reduced = TruncatedSVD(n_components=50, random_state=0).fit_transform(X_train)\n",
    "X_Train_embedded = TSNE(n_components=2, perplexity=40, verbose=2).fit_transform(X_train)\n",
    "\n",
    "#some convert lists of lists to 2 dataframes (df_train_neg, df_train_pos) depending on the label - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_Train_embedded[:,0], X_Train_embedded[:,1], marker='o', c='red')\n",
    "# plt.scatter(X_Train_embedded[:,0], X_Train_embedded[:,1], marker='o', c='blue')\n",
    "# plt.scatter(X_train, y_train, marker='o', c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = np.expand_dims(y_train,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = np.concatenate([X_Train_embedded,y_train_new],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.DataFrame(data_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat[2] = df_concat[2].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_concat[df_concat[2] == 0][0], df_concat[df_concat[2] == 0][1], marker='o', c='red')\n",
    "plt.scatter(df_concat[df_concat[2] == 1][0], df_concat[df_concat[2] == 1][1], marker='o', c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test\",type=\"numpy\")\n",
    "model.save(\"test\",type=\"pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
